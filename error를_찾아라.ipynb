{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "error를 찾아라.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOV/VxFyxQc+pVOUx9Mjbec",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coreight98/Paran_ajou_Project_Anything/blob/main/error%EB%A5%BC_%EC%B0%BE%EC%95%84%EB%9D%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8un6D9fOKDUb",
        "outputId": "049fe548-14f0-48fc-f111-016144877e9a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKZUCQiyKERe"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import time\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "sA71fawSKG4l",
        "outputId": "002188d7-32a0-4e14-a01d-b06c16726934"
      },
      "source": [
        "train_location = './drive/MyDrive/data/pattern/'\n",
        "\n",
        "X = np.empty((0, 4), dtype=int)\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # 첫번째층\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 8, kernel_size=3,stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 두번째층\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(8, 16, kernel_size=3,stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 전결합층 \n",
        "        self.fc = torch.nn.Linear(50176, 5, bias=True)\n",
        "\n",
        "        # 전결합층 한정으로 가중치 초기화\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        global X\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
        "        out = self.fc(out)\n",
        "        X = np.append(X,out.detach().numpy())\n",
        "        return out\n",
        "\n",
        "class PatternDataset():\n",
        "    def __init__(self, image, mode, transforms):\n",
        "        super().__init__()\n",
        "        self.image = image\n",
        "        self.mode = mode\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.image[index]\n",
        "        image = Image.open(train_location + image_name)\n",
        "        image = image.resize((224,224))\n",
        "\n",
        "        if self.mode == 'train' :\n",
        "            image = self.transforms(image)\n",
        "            label=1\n",
        "            return image,label\n",
        "        elif self.mode == 'test':\n",
        "            image = self.transforms(image)\n",
        "            label=1\n",
        "            return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image)\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #데이터 셋 불러오고 정규화\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.Grayscale(num_output_channels=1),\n",
        "         transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5),(0.5))\n",
        "          ]\n",
        "    )\n",
        "\n",
        "    train_images = os.listdir(train_location)\n",
        "    # test_images = os.listdir(test_location)\n",
        "    print(\"--Train Images--\")\n",
        "    print(\"Num of All Images: \", len(train_images))\n",
        "\n",
        "    # 데이터 셋 생성\n",
        "    train_dataset = PatternDataset(train_images, mode='train', transforms=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
        "    \n",
        "    net = CNN()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print (device,\"로 학습\")\n",
        "\n",
        "    #신경망 학습하기\n",
        "    for i, data in enumerate(trainloader,0):\n",
        "        inputs, labels = data  # data입력\n",
        "        outputs = net(inputs)\n",
        "\n",
        "\n",
        "    print('Finished Training')\n",
        "    PATH = './drive/MyDrive/data/Pattern_net.pth'\n",
        "    torch.save(net, PATH)\n",
        "\n",
        "\n",
        "######################################################################\n",
        "\n",
        "\n",
        "    img=PIL.Image.open('./drive/MyDrive/data/pattern/0002.jpg')\n",
        "    img = img.resize((224,224))\n",
        "    emp = torch.empty(1,1,224,224)\n",
        "    img_t =transform(img)\n",
        "    emp[0] = img_t\n",
        "    input = net(emp)\n",
        "\n",
        "    X = np.reshape(X,(1280,5)) #1281개 5개tensor\n",
        "    Y = np.ones((1280,1),dtype=int)\n",
        "\n",
        "    reg = KNeighborsClassifier(n_neighbors=4)\n",
        "    reg.fit(X,Y)\n",
        "    l = reg.kneighbors(input.detach().numpy(),n_neighbors=4,return_distance=False)\n",
        "\n",
        "    l.sort()\n",
        "    for i in l:\n",
        "      temp = np.empty((0,4),dtype=int)\n",
        "      temp = np.append(temp, X[i])\n",
        "    temp = np.reshape(temp,(4,5))\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    print(len(dataiter))\n",
        "    count = 0\n",
        "    print(l)\n",
        "    print(l[0][0])\n",
        "    index=0\n",
        "    \n",
        "    images = torch.empty(4,1,224,224)\n",
        "    \n",
        "    while(index<4):\n",
        "      if count < l[0][index]:\n",
        "        img=dataiter.next()\n",
        "        count+=4\n",
        "      else:\n",
        "        print(\"find!\")\n",
        "        #l[0][index]-count 한 값을 인덱스로 dataiter에서 출력\n",
        "        # print(img[0][l[0][index]-count][0])\n",
        "        images[index][0] = img[0][l[0][index]-count][0]\n",
        "        dataiter.next()\n",
        "        count+=4\n",
        "        index+=1\n",
        "    #이미지 출력\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "    from IPython.display import Image \n",
        "    img=Image('./drive/MyDrive/data/pattern/0002.jpg')\n",
        "    display(img)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Train Images--\n",
            "Num of All Images:  1280\n",
            "cuda 로 학습\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3900133129da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#1281개 5개tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    297\u001b[0m            [5, 6]])\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 6405 into shape (1280,5)"
          ]
        }
      ]
    }
  ]
}