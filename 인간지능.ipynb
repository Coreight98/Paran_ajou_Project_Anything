{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "인간지능.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOLvair2xkvbfebcfo7ohw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coreight98/Paran_ajou_Project_Anything/blob/main/%EC%9D%B8%EA%B0%84%EC%A7%80%EB%8A%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHm3i95oDaKT"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFV3MdPCDkQQ"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import time\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGrQwV-4DlEw"
      },
      "source": [
        "train_location = './drive/MyDrive/data/img/train/'\n",
        "# test_location = './drive/MyDrive/data/img/val/'\n",
        "\n",
        "X = np.empty((0, 4), dtype=int)\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # 첫번째층\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 8, kernel_size=3,stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 두번째층\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(8, 16, kernel_size=3,stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 전결합층 \n",
        "        self.fc = torch.nn.Linear(50176, 5, bias=True)\n",
        "\n",
        "        # 전결합층 한정으로 가중치 초기화\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        global X\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
        "        out = self.fc(out)\n",
        "        X = np.append(X,out.detach().numpy())\n",
        "        return out\n",
        "\n",
        "class FurnitureDataset():\n",
        "    def __init__(self, image, class_to_int, mode, transforms):\n",
        "        super().__init__()\n",
        "        self.image = image\n",
        "        self.class_to_int = class_to_int\n",
        "        self.mode = mode\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.image[index]\n",
        "        image = Image.open(train_location + image_name)\n",
        "        image = image.resize((224,224))\n",
        "\n",
        "        \n",
        "        #레이블 입력\n",
        "        label = self.class_to_int[image_name.split('.')[0]]\n",
        "        label = torch.tensor(label,dtype=torch.long)\n",
        "        #이미지 변형 적용\n",
        "        image = self.transforms(image)\n",
        "        return image, label\n",
        "       \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image)\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #데이터 셋 불러오고 정규화\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.Grayscale(num_output_channels=1),\n",
        "         transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5),(0.5))\n",
        "          ]\n",
        "    )\n",
        "    \n",
        "    train_images = os.listdir(train_location)\n",
        "    # test_images = os.listdir(test_location)\n",
        "    print(\"--Train Images--\")\n",
        "    print(\"Num of All Images: \", len(train_images))\n",
        "    beds_list = [img for img in train_images if img.split(\".\")[0] == \"bed\"]\n",
        "    chairs_list = [img for img in train_images if img.split(\".\")[0] == \"chair\"]\n",
        "    sofas_list = [img for img in train_images if img.split(\".\")[0] == \"sofa\"]\n",
        "    swivelchair_list = [img for img in train_images if img.split(\".\")[0] == \"swivelchair\"]\n",
        "    tables_list = [img for img in train_images if img.split(\".\")[0] == \"table\"]\n",
        "    print(\"Num of Beds Images: \", len(beds_list))\n",
        "    print(\"Num of chairs Images: \", len(chairs_list))\n",
        "    print(\"Num of sofas Images: \", len(sofas_list))\n",
        "    print(\"Num of swivelchairs Images: \", len(swivelchair_list))\n",
        "    print(\"Num of tables Images: \", len(tables_list))\n",
        "\n",
        "    # 레이블 구분\n",
        "    class_to_int = {\"bed\": 0, \"chair\": 1, \"swivelchair\": 2, \"sofa\": 3, \"table\": 4}\n",
        "    int_to_class = {0: \"bed\", 1: \"chair\", 2: \"swivelchair\", 3: \"sofa\", 4: \"table\"}\n",
        "    classes = ['bed', 'chair', 'swivelchair', 'sofa', 'table']\n",
        "\n",
        "    # 데이터 셋 생성\n",
        "    train_dataset = PatternDataset(train_images, mode='train', transforms=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
        "    \n",
        "    net = CNN()\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print (device,\"로 학습\")\n",
        "\n",
        "    #신경망 학습하기\n",
        "    for i, data in enumerate(trainloader,0):\n",
        "        inputs, labels = data  # data입력\n",
        "        outputs = net(inputs)\n",
        "\n",
        "    np.save('./drive/MyDrive/data/accuracy.npy', X)\n",
        "    print('Finished Training')\n",
        "    PATH = './drive/MyDrive/data/accuracy_net.pth'\n",
        "    torch.save(net, PATH)\n",
        "\n",
        "\n",
        "######################################################################\n",
        "\n",
        "    # net = torch.load(PATH)\n",
        "    # net.eval()\n",
        "    # X = np.load('./drive/MyDrive/data/accuracy.npy')\n",
        "    # print(X)\n",
        "    img=PIL.Image.open('./drive/MyDrive/data/img/train/bed.1.jpg')\n",
        "    img = img.resize((224,224))\n",
        "    emp = torch.empty(1,1,224,224)\n",
        "    img_t =transform(img)\n",
        "    emp[0] = img_t\n",
        "    input = net(emp)\n",
        "\n",
        "    X = np.reshape(X,(4024,5)) #1281개 5개tensor\n",
        "    Y = np.ones((4024,1),dtype=int)\n",
        "\n",
        "    reg = KNeighborsClassifier(n_neighbors=4)\n",
        "    reg.fit(X,Y)\n",
        "    l = reg.kneighbors(input.detach().numpy(),n_neighbors=4,return_distance=False)\n",
        "    \n",
        "    l.sort()\n",
        "    print(l)\n",
        "\n",
        "    for i in l:\n",
        "      temp = np.empty((0,4),dtype=int)\n",
        "      temp = np.append(temp, X[i])\n",
        "    temp = np.reshape(temp,(4,5))\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    \n",
        "    count = 0\n",
        "    \n",
        "    index=0\n",
        "    \n",
        "    images = torch.empty(4,1,224,224)\n",
        "\n",
        "\n",
        "    while(index<4):\n",
        "      if count < l[0][index]:\n",
        "        imgg=img\n",
        "        img=dataiter.next()\n",
        "        count+=4\n",
        "      else:\n",
        "        print(\"find!\")\n",
        "        #l[0][index]-count 한 값을 인덱스로 dataiter에서 출력\n",
        "        k=count-l[0][index]\n",
        "        print(k)\n",
        "        if k == 0:\n",
        "          images[index][0] = img[0][k][0]\n",
        "        else:\n",
        "          images[index][0] = imgg[0][4-k][0]\n",
        "        count+=4\n",
        "        index+=1\n",
        "        if index != 4:\n",
        "          dataiter.next()\n",
        "        \n",
        "    #이미지 출력\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "    from IPython.display import Image \n",
        "    img=Image('./drive/MyDrive/data/img/train/bed.1.jpg')\n",
        "    display(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}