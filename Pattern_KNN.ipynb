{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pattern_KNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOYw6+QP8ksdC3yslfETEP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coreight98/Paran_ajou_Project_Anything/blob/main/Pattern_KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1pdvl8J5esu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HiCabSr5p0F"
      },
      "source": [
        "train_location = './drive/MyDrive/data/DTD/'\n",
        "test_location = './drive/MyDrive/data/DTD_test/'\n",
        "\n",
        "X = np.empty((0, 4), dtype=int)\n",
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # 첫번째층\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(3, 32, kernel_size=3,stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(num_features=32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=4, stride=4))\n",
        "\n",
        "        # 두번째층\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3,stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        # 세번째층\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(64, 256, kernel_size=3,stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(num_features=256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        # 네번째층\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(256, 512, kernel_size=3,stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(num_features=512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        # 다섯번째층\n",
        "        self.layer5 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(512, 1024, kernel_size=3,stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(num_features=1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 6번째층\n",
        "        self.layer6 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1024, 2048, kernel_size=3,stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(num_features=2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "       \n",
        "        # 전결합층 \n",
        "        self.fc = torch.nn.Linear(2048, 38, bias=True)\n",
        "\n",
        "        # 전결합층 한정으로 가중치 초기화\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        global X\n",
        "        out = self.layer1(x)\n",
        "        # print(out.shape)\n",
        "        out = self.layer2(out)\n",
        "        # print(out.shape)\n",
        "        out = self.layer3(out)\n",
        "        # print(out.shape)\n",
        "        out = self.layer4(out)\n",
        "        # print(out.shape)\n",
        "        out = self.layer5(out)\n",
        "        # print(out.shape)\n",
        "        out = self.layer6(out)\n",
        "        # print(out.shape)\n",
        "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
        "        out = self.fc(out)\n",
        "        X = np.append(X,out.detach().numpy())\n",
        "        return out\n",
        "\n",
        "class PatternDataset():\n",
        "    def __init__(self, image, class_to_int, mode, transforms):\n",
        "        super().__init__()\n",
        "        self.image = image\n",
        "        self.class_to_int = class_to_int\n",
        "        self.mode = mode\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        if self.mode == 'train' :\n",
        "            image_name = self.image[index]\n",
        "            image = Image.open(train_location + image_name)\n",
        "            image = image.resize((224,224))\n",
        "            #레이블 입력\n",
        "            label = self.class_to_int[image_name.split('_')[0]]\n",
        "            label = torch.tensor(label,dtype=torch.long)\n",
        "            #이미지 변형 적용\n",
        "            image = self.transforms(image)\n",
        "            return image, label\n",
        "        elif self.mode == 'test':\n",
        "            image_name = self.image[index]\n",
        "            image = Image.open(test_location + image_name)\n",
        "            image = image.resize((224,224))\n",
        "            #레이블 입력\n",
        "            label = self.class_to_int[image_name.split('_')[0]]\n",
        "            label = torch.tensor(label,dtype=torch.long)\n",
        "            #이미지 변형 적용용\n",
        "            image = self.transforms(image)\n",
        "            return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image)\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB_BeYeY6Snr"
      },
      "source": [
        "PATH = './drive/MyDrive/DTD_save/net1.pth'\n",
        "net = torch.load(PATH)\n",
        "net.eval()\n",
        "X = np.load('./drive/MyDrive/DTD_save/X1.npy')\n",
        "\n",
        "img=PIL.Image.open('./drive/MyDrive/DTD_test/???.jpg')\n",
        "img = img.resize((224,224))\n",
        "emp = torch.empty(1,1,224,224)\n",
        "img_t =transform(img)\n",
        "emp[0] = img_t\n",
        "input = net(emp)\n",
        "\n",
        "X = np.reshape(X,(1281,5)) #1281개 5개tensor\n",
        "Y = np.ones((1281,1),dtype=int)\n",
        "\n",
        "reg = KNeighborsClassifier(n_neighbors=4)\n",
        "reg.fit(X,Y)\n",
        "l = reg.kneighbors(input.detach().numpy(),n_neighbors=4,return_distance=False)\n",
        "\n",
        "l.sort()\n",
        "print(l)\n",
        "\n",
        "for i in l:\n",
        "  temp = np.empty((0,4),dtype=int)\n",
        "  temp = np.append(temp, X[i])\n",
        "temp = np.reshape(temp,(4,5))\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "\n",
        "count = 0\n",
        "\n",
        "index=0\n",
        "\n",
        "images = torch.empty(4,1,224,224)\n",
        "\n",
        "\n",
        "while(index<4):\n",
        "  if count < l[0][index]:\n",
        "    imgg=img\n",
        "    img=dataiter.next()\n",
        "    count+=4\n",
        "  else:\n",
        "    print(\"find!\")\n",
        "    #l[0][index]-count 한 값을 인덱스로 dataiter에서 출력\n",
        "    k=count-l[0][index]\n",
        "    print(k)\n",
        "    if k == 0:\n",
        "      images[index][0] = img[0][k][0]\n",
        "    else:\n",
        "      images[index][0] = imgg[0][4-k][0]\n",
        "    count+=4\n",
        "    index+=1\n",
        "    if index != 4:\n",
        "      dataiter.next()\n",
        "    \n",
        "#이미지 출력\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "from IPython.display import Image \n",
        "img=Image('./drive/MyDrive/DTD_test/???.jpg')\n",
        "display(img)\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}