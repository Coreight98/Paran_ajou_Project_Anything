{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "인간지능.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coreight98/Paran_ajou_Project_Anything/blob/main/%EC%9D%B8%EA%B0%84%EC%A7%80%EB%8A%A56.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHm3i95oDaKT",
        "outputId": "2ea896cc-e9eb-484d-e57c-b7d94fd2b063"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFV3MdPCDkQQ"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import time\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGrQwV-4DlEw",
        "outputId": "dd69f9ca-b573-47af-ce21-ef8ff9286094"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print (device,\"로 학습\")\n",
        "\n",
        "# 랜덤 시드 고정\n",
        "torch.manual_seed(777)\n",
        "torch.cuda.manual_seed(777)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "random.seed(777)\n",
        "np.random.seed(777)\n",
        "\n",
        "# GPU 사용 가능일 경우 랜덤 시드 고정\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "train_location = './drive/MyDrive/data/img/train/'\n",
        "# test_location = './drive/MyDrive/data/img/val/'\n",
        "\n",
        "X = np.empty((0, 4), dtype=int)\n",
        "Y = np.empty((0, 1), dtype=int)\n",
        "I=0\n",
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # 첫번째층\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 16, kernel_size=2,stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 두번째층\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(16, 32, kernel_size=2,stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        # 세번째층\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=2,stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        # 네번째층\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=2,stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=3))\n",
        "        \n",
        "        # 다섯번째층\n",
        "        self.layer5 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(128, 256, kernel_size=2,stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=3))\n",
        "\n",
        "        # 6번째층\n",
        "        self.layer6 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(256, 512, kernel_size=2,stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=3))\n",
        "        \n",
        "        # 전결합층 \n",
        "        self.fc = torch.nn.Linear(512, 5, bias=True)\n",
        "\n",
        "        # 전결합층 한정으로 가중치 초기화\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        global X,I\n",
        "        out = self.layer1(x)\n",
        "      \n",
        "        out = self.layer2(out)\n",
        "   \n",
        "        out = self.layer3(out)\n",
        "     \n",
        "        out = self.layer4(out)\n",
        "\n",
        "        out = self.layer5(out)\n",
        "        \n",
        "        out = self.layer6(out)\n",
        "        \n",
        "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
        "        out = self.fc(out)\n",
        "        if I<4024:\n",
        "          X = np.append(X,out.detach().numpy())\n",
        "          I+=1\n",
        "        if I !=9999 : print(I)\n",
        "        return out\n",
        "\n",
        "class FurnitureDataset():\n",
        "    def __init__(self, image, class_to_int, mode, transforms):\n",
        "        super().__init__()\n",
        "        self.image = image\n",
        "        self.class_to_int = class_to_int\n",
        "        self.mode = mode\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.image[index]\n",
        "        image = Image.open(train_location + image_name)\n",
        "        image = image.resize((224,224))\n",
        "\n",
        "        \n",
        "        #레이블 입력\n",
        "        global Y\n",
        "        label = self.class_to_int[image_name.split('.')[0]]\n",
        "        label = torch.tensor(label,dtype=torch.long)\n",
        "        Y = np.append(Y,label)\n",
        "        #이미지 변형 적용\n",
        "        image = self.transforms(image)\n",
        "        return image, label\n",
        "       \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image)\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #데이터 셋 불러오고 정규화\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.Grayscale(num_output_channels=1),\n",
        "         transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5),(0.5))\n",
        "          ]\n",
        "    )\n",
        "    \n",
        "    train_images = os.listdir(train_location)\n",
        "    # test_images = os.listdir(test_location)\n",
        "    print(\"--Train Images--\")\n",
        "    print(\"Num of All Images: \", len(train_images))\n",
        "    beds_list = [img for img in train_images if img.split(\".\")[0] == \"bed\"]\n",
        "    chairs_list = [img for img in train_images if img.split(\".\")[0] == \"chair\"]\n",
        "    sofas_list = [img for img in train_images if img.split(\".\")[0] == \"sofa\"]\n",
        "    swivelchair_list = [img for img in train_images if img.split(\".\")[0] == \"swivelchair\"]\n",
        "    tables_list = [img for img in train_images if img.split(\".\")[0] == \"table\"]\n",
        "    print(\"Num of Beds Images: \", len(beds_list))\n",
        "    print(\"Num of chairs Images: \", len(chairs_list))\n",
        "    print(\"Num of sofas Images: \", len(sofas_list))\n",
        "    print(\"Num of swivelchairs Images: \", len(swivelchair_list))\n",
        "    print(\"Num of tables Images: \", len(tables_list))\n",
        "\n",
        "    # # 레이블 구분\n",
        "    class_to_int = {\"bed\": 0, \"chair\": 1, \"swivelchair\": 2, \"sofa\": 3, \"table\": 4}\n",
        "    int_to_class = {0: \"bed\", 1: \"chair\", 2: \"swivelchair\", 3: \"sofa\", 4: \"table\"}\n",
        "    classes = ['bed', 'chair', 'swivelchair', 'sofa', 'table']\n",
        "\n",
        "    # 데이터 셋 생성\n",
        "    train_dataset = FurnitureDataset(train_images, class_to_int, mode='train', transforms=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
        "    \n",
        "    #net = CNN()\n",
        "    \n",
        "    \n",
        "\n",
        "    #신경망 학습하기\n",
        "    #for i, data in enumerate(trainloader,0):\n",
        "    #    inputs, labels = data  # data입력\n",
        "    #    outputs = net(inputs)\n",
        "\n",
        "    #np.save('./drive/MyDrive/data/accuracy6.npy', X)\n",
        "    #np.save('./drive/MyDrive/data/accuracy6_label.npy', Y)\n",
        "\n",
        "    #print('Finished Training')\n",
        "    PATH = './drive/MyDrive/data/accuracy6_net.pth'\n",
        "    #torch.save(net, PATH)\n",
        "\n",
        "\n",
        "######################################################################\n",
        "\n",
        "    net = torch.load(PATH)\n",
        "    net.eval()\n",
        "    \n",
        "    X = np.load('./drive/MyDrive/data/accuracy6.npy')\n",
        "    Y = np.load('./drive/MyDrive/data/accuracy6_label.npy')\n",
        "    \n",
        "    X = np.reshape(X,(4024,5)) #1281개 5개tensor\\\n",
        "    Y = np.reshape(Y,(4024,1))\n",
        "    reg = KNeighborsClassifier(n_neighbors=10)\n",
        "    reg.fit(X,Y)\n",
        "\n",
        "    sum_accuracy=0\n",
        "    for i in range(1,50) :\n",
        "      print(\"#%d\"%i)\n",
        "      I=9999\n",
        "      img=PIL.Image.open('./drive/MyDrive/data/img/val/swivelchair.%d.jpg'%i)\n",
        "      input_label = class_to_int[\"swivelchair\"]\n",
        "      img = img.resize((224,224))\n",
        "      emp = torch.empty(1,1,224,224)\n",
        "      img_t =transform(img)\n",
        "      emp[0] = img_t\n",
        "      input = net(emp)\n",
        "      neighbor_index= reg.kneighbors(input.detach().numpy(),n_neighbors=10,return_distance=False)\n",
        "      neighbor_index.sort()\n",
        "      # print(neighbor_index)\n",
        "      for i in neighbor_index:\n",
        "        temp = np.empty((0,5),dtype=int)\n",
        "        temp = np.append(temp, X[i])\n",
        "      temp = np.reshape(temp,(10,5))\n",
        "      \n",
        "      Y_list = Y[neighbor_index].tolist()\n",
        "      correct=0.0\n",
        "      # print(\"Input label: \",input_label)\n",
        "      for i in Y_list:\n",
        "        print(i)\n",
        "        for j in i:\n",
        "          if j[0] == input_label:\n",
        "            correct+=1\n",
        "      print(\"accuracy : %f\"%(correct/10))\n",
        "      sum_accuracy+=correct/10\n",
        "    print(\"Final accuracy : %f\"%(sum_accuracy/50))\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "  \n",
        "    \n",
        "\n",
        "    # dataiter = iter(trainloader)\n",
        "    # img = dataiter.next()\n",
        "    # count = 0\n",
        "    # index=0\n",
        "    # images = torch.empty(10,1,224,224)\n",
        "    # correct=0\n",
        "\n",
        "    # while(index<10):\n",
        "    #   imgg = img\n",
        "    #   if count < neighbor_index[0][index]:\n",
        "    #     img=dataiter.next()\n",
        "    #     count+=4\n",
        "    #   else:\n",
        "    #     #l[0][index]-count 한 값을 인덱스로 dataiter에서 출력\n",
        "    #     k=count-neighbor_index[0][index]\n",
        "    #     if k == 0:\n",
        "    #       images[index][0] = img[0][k][0]\n",
        "    #       label=classes[img[1][k].item()]\n",
        "    #       print(label,count,count-neighbor_index[0][index])\n",
        "    #       if img[1][k].item()==input_label:\n",
        "    #         correct+=1\n",
        "    #     else:\n",
        "    #       images[index][0] = img[0][4-k][0]\n",
        "    #       label=classes[img[1][4-k].item()]\n",
        "    #       print(label,count,count-neighbor_index[0][index])\n",
        "    #       if img[1][4-k].item()==input_label:\n",
        "    #         correct+=1\n",
        "    #     count+=4\n",
        "    #     index+=1\n",
        "    #     if index != 4:\n",
        "    #       dataiter.next()\n",
        "    # print(\"accuracy : \",correct/10)\n",
        "\n",
        "    # #이미지 출력\n",
        "    # imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "    # from IPython.display import Image\n",
        "    # img=Image('./drive/MyDrive/data/img/train/swivelchair.10.jpg')\n",
        "    # display(img)\n",
        "    # from PIL import Image"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda 로 학습\n",
            "--Train Images--\n",
            "Num of All Images:  4024\n",
            "Num of Beds Images:  900\n",
            "Num of chairs Images:  900\n",
            "Num of sofas Images:  900\n",
            "Num of swivelchairs Images:  900\n",
            "Num of tables Images:  424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "#1\n",
            "[[2], [4], [3], [2], [1], [1], [1], [0], [1], [1]]\n",
            "accuracy : 0.200000\n",
            "#2\n",
            "[[2], [2], [2], [2], [2], [4], [4], [2], [2], [2]]\n",
            "accuracy : 0.800000\n",
            "#3\n",
            "[[2], [2], [4], [3], [3], [1], [1], [3], [0], [0]]\n",
            "accuracy : 0.200000\n",
            "#4\n",
            "[[2], [2], [2], [2], [1], [1], [1], [1], [1], [1]]\n",
            "accuracy : 0.400000\n",
            "#5\n",
            "[[2], [4], [3], [3], [2], [2], [1], [3], [0], [0]]\n",
            "accuracy : 0.300000\n",
            "#6\n",
            "[[2], [2], [4], [4], [4], [2], [2], [1], [0], [0]]\n",
            "accuracy : 0.400000\n",
            "#7\n",
            "[[2], [4], [3], [1], [3], [0], [0], [0], [0], [0]]\n",
            "accuracy : 0.100000\n",
            "#8\n",
            "[[3], [3], [3], [3], [3], [1], [3], [0], [0], [0]]\n",
            "accuracy : 0.000000\n",
            "#9\n",
            "[[2], [2], [2], [3], [3], [3], [2], [1], [1], [3]]\n",
            "accuracy : 0.400000\n",
            "#10\n",
            "[[2], [4], [4], [3], [1], [1], [1], [1], [0], [0]]\n",
            "accuracy : 0.100000\n",
            "#11\n",
            "[[2], [2], [2], [1], [1], [1], [1], [1], [0], [0]]\n",
            "accuracy : 0.300000\n",
            "#12\n",
            "[[2], [2], [3], [1], [1], [1], [1], [0], [0], [0]]\n",
            "accuracy : 0.200000\n",
            "#13\n",
            "[[2], [1], [1], [3], [0], [0], [0], [0], [0], [0]]\n",
            "accuracy : 0.100000\n",
            "#14\n",
            "[[2], [2], [2], [2], [2], [2], [1], [1], [1], [1]]\n",
            "accuracy : 0.600000\n",
            "#15\n",
            "[[3], [3], [3], [3], [3], [3], [3], [3], [0], [0]]\n",
            "accuracy : 0.000000\n",
            "#16\n",
            "[[2], [2], [3], [3], [2], [2], [2], [2], [1], [1]]\n",
            "accuracy : 0.600000\n",
            "#17\n",
            "[[2], [2], [4], [3], [2], [2], [2], [1], [0], [1]]\n",
            "accuracy : 0.500000\n",
            "#18\n",
            "[[2], [4], [4], [4], [3], [3], [3], [2], [2], [0]]\n",
            "accuracy : 0.300000\n",
            "#19\n",
            "[[2], [3], [3], [2], [1], [1], [1], [0], [0], [0]]\n",
            "accuracy : 0.200000\n",
            "#20\n",
            "[[4], [4], [3], [3], [2], [2], [1], [0], [0], [0]]\n",
            "accuracy : 0.200000\n",
            "#21\n",
            "[[4], [4], [4], [3], [3], [3], [2], [1], [3], [0]]\n",
            "accuracy : 0.100000\n",
            "#22\n",
            "[[2], [4], [4], [4], [3], [2], [1], [0], [0], [1]]\n",
            "accuracy : 0.200000\n",
            "#23\n",
            "[[2], [2], [2], [3], [1], [1], [1], [1], [3], [0]]\n",
            "accuracy : 0.300000\n",
            "#24\n",
            "[[2], [4], [2], [2], [2], [2], [2], [2], [1], [1]]\n",
            "accuracy : 0.700000\n",
            "#25\n",
            "[[2], [2], [3], [3], [2], [2], [2], [1], [1], [1]]\n",
            "accuracy : 0.500000\n",
            "#26\n",
            "[[2], [2], [2], [2], [2], [2], [2], [2], [2], [2]]\n",
            "accuracy : 1.000000\n",
            "#27\n",
            "[[2], [2], [2], [2], [3], [1], [1], [0], [0], [0]]\n",
            "accuracy : 0.400000\n",
            "#28\n",
            "[[2], [4], [3], [1], [1], [1], [1], [0], [0], [0]]\n",
            "accuracy : 0.100000\n",
            "#29\n",
            "[[2], [2], [4], [3], [3], [1], [1], [1], [1], [1]]\n",
            "accuracy : 0.200000\n",
            "#30\n",
            "[[2], [2], [2], [2], [2], [2], [2], [4], [4], [3]]\n",
            "accuracy : 0.700000\n",
            "#31\n",
            "[[2], [2], [2], [2], [2], [2], [3], [2], [0], [0]]\n",
            "accuracy : 0.700000\n",
            "#32\n",
            "[[2], [3], [2], [2], [1], [3], [0], [0], [0], [1]]\n",
            "accuracy : 0.300000\n",
            "#33\n",
            "[[2], [2], [2], [2], [2], [4], [3], [3], [3], [3]]\n",
            "accuracy : 0.500000\n",
            "#34\n",
            "[[2], [2], [3], [3], [3], [2], [1], [1], [0], [0]]\n",
            "accuracy : 0.300000\n",
            "#35\n",
            "[[4], [4], [2], [1], [1], [1], [1], [1], [0], [0]]\n",
            "accuracy : 0.100000\n",
            "#36\n",
            "[[2], [4], [3], [2], [2], [1], [1], [1], [0], [0]]\n",
            "accuracy : 0.300000\n",
            "#37\n",
            "[[2], [2], [3], [2], [2], [2], [2], [2], [2], [1]]\n",
            "accuracy : 0.800000\n",
            "#38\n",
            "[[2], [2], [2], [4], [4], [4], [4], [1], [3], [1]]\n",
            "accuracy : 0.300000\n",
            "#39\n",
            "[[4], [4], [3], [3], [2], [1], [1], [1], [1], [0]]\n",
            "accuracy : 0.100000\n",
            "#40\n",
            "[[2], [2], [4], [4], [4], [2], [2], [2], [2], [1]]\n",
            "accuracy : 0.600000\n",
            "#41\n",
            "[[2], [2], [2], [2], [2], [4], [4], [3], [1], [1]]\n",
            "accuracy : 0.500000\n",
            "#42\n",
            "[[2], [2], [2], [3], [3], [3], [2], [0], [0], [0]]\n",
            "accuracy : 0.400000\n",
            "#43\n",
            "[[2], [3], [3], [3], [3], [2], [1], [1], [0], [0]]\n",
            "accuracy : 0.200000\n",
            "#44\n",
            "[[2], [4], [4], [2], [1], [1], [0], [0], [1], [0]]\n",
            "accuracy : 0.200000\n",
            "#45\n",
            "[[2], [4], [4], [3], [2], [2], [2], [2], [2], [1]]\n",
            "accuracy : 0.600000\n",
            "#46\n",
            "[[2], [2], [2], [4], [4], [2], [2], [2], [2], [1]]\n",
            "accuracy : 0.700000\n",
            "#47\n",
            "[[2], [4], [3], [3], [1], [1], [1], [1], [0], [0]]\n",
            "accuracy : 0.100000\n",
            "#48\n",
            "[[2], [2], [4], [3], [1], [1], [3], [0], [0], [0]]\n",
            "accuracy : 0.200000\n",
            "#49\n",
            "[[2], [1], [1], [3], [3], [0], [0], [0], [0], [0]]\n",
            "accuracy : 0.100000\n",
            "Final accuracy : 0.342000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}