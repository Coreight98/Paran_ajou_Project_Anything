{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Furniture_Classify.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKlOVBre/H97lU7YCp41Ic",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coreight98/Paran_ajou_Project_Anything/blob/main/CNN_Furniture_Classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBfxdTLbVPAc"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from PIL import Image\r\n",
        "from sklearn .model_selection import train_test_split\r\n",
        "from torchvision.models import resnet50\r\n",
        "import time\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdYW_4dSZ7Ih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "f2c04139-51a3-45cc-9c1a-4ad96295c9d7"
      },
      "source": [
        "train_location = './img/train/'\r\n",
        "test_location = './img/val/'\r\n",
        "\r\n",
        "#합성곱 신경망(Convolution Neural Network) 정의하기\r\n",
        "# class Net(nn.Module):\r\n",
        "#     def __init__(self):\r\n",
        "#         super(Net, self).__init__()\r\n",
        "#         self.conv1 = nn.Conv2d(3, 6, 5)\r\n",
        "#         self.pool = nn.MaxPool2d(2, 2)\r\n",
        "#         self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
        "#         self.fc1 = nn.Linear(179776, 17000)\r\n",
        "#         self.fc2 = nn.Linear(1700, 170)\r\n",
        "#         self.fc3 = nn.Linear(170, 10)\r\n",
        "#     def forward(self, x):\r\n",
        "#         x = self.pool(F.relu(self.conv1(x)))\r\n",
        "#         x = self.pool(F.relu(self.conv2(x)))\r\n",
        "#         x = x.view(-1, 179776)\r\n",
        "#         x = F.relu(self.fc1(x))\r\n",
        "#         x = F.relu(self.fc2(x))\r\n",
        "#         x = self.fc3(x)\r\n",
        "#         return x\r\n",
        "\r\n",
        "class CNN(torch.nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(CNN, self).__init__()\r\n",
        "        # 첫번째층\r\n",
        "        self.layer1 = torch.nn.Sequential(,\r\n",
        "            torch.nn.Conv2d(1, 8, 4),#패딩추가\r\n",
        "            torch.nn.ReLU(),\r\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
        "\r\n",
        "        # 두번째층\r\n",
        "        self.layer2 = torch.nn.Sequential(\r\n",
        "            torch.nn.Conv2d(8, 16, 4),\r\n",
        "            torch.nn.ReLU(),\r\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
        "\r\n",
        "        # 전결합층 \r\n",
        "        self.fc = torch.nn.Linear(44944, 5, bias=True)\r\n",
        "\r\n",
        "        # 전결합층 한정으로 가중치 초기화\r\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = self.layer1(x)\r\n",
        "        out = self.layer2(out)\r\n",
        "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\r\n",
        "        out = self.fc(out)\r\n",
        "        return out\r\n",
        "\r\n",
        "class FurnitureDataset():\r\n",
        "    def __init__(self, image, class_to_int, mode, transforms):\r\n",
        "        super().__init__()\r\n",
        "        self.image = image\r\n",
        "        self.class_to_int = class_to_int\r\n",
        "        self.mode = mode\r\n",
        "        self.transforms = transforms\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        image_name = self.image[index]\r\n",
        "        image = Image.open(train_location + image_name)\r\n",
        "        image = image.resize((224,224))\r\n",
        "\r\n",
        "        if self.mode == 'train' :\r\n",
        "            #레이블 입력\r\n",
        "            label = self.class_to_int[image_name.split('.')[0]]\r\n",
        "            label = torch.tensor(label,dtype=torch.long)\r\n",
        "            #이미지 변형 적용\r\n",
        "            image = self.transforms(image)\r\n",
        "            return image, label\r\n",
        "        elif self.mode == 'test':\r\n",
        "            #이미지 변형 적용용\r\n",
        "            image = self.transforms(image)\r\n",
        "            return image\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.image)\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    #데이터 셋 불러오고 정규화\r\n",
        "    transform = transforms.Compose(\r\n",
        "        [transforms.ToTensor(),\r\n",
        "         #transforms.Grayscale(num_output_channels=1),\r\n",
        "          transforms.Normalize((0.5),(0.5))]\r\n",
        "    )\r\n",
        "\r\n",
        "    train_images = os.listdir(train_location)\r\n",
        "    test_images = os.listdir(test_location)\r\n",
        "    print(\"--Train Images--\")\r\n",
        "    print(\"Num of All Images: \", len(train_images))\r\n",
        "\r\n",
        "    beds_list = [img for img in train_images if img.split(\".\")[0] == \"bed\"]\r\n",
        "    chairs_list = [img for img in train_images if img.split(\".\")[0] == \"chair\"]\r\n",
        "    sofas_list = [img for img in train_images if img.split(\".\")[0] == \"sofa\"]\r\n",
        "    swivelchair_list = [img for img in train_images if img.split(\".\")[0] == \"swivelchair\"]\r\n",
        "    tables_list = [img for img in train_images if img.split(\".\")[0] == \"table\"]\r\n",
        "    print(\"Num of Beds Images: \", len(beds_list))\r\n",
        "    print(\"Num of chairs Images: \", len(chairs_list))\r\n",
        "    print(\"Num of sofas Images: \", len(sofas_list))\r\n",
        "    print(\"Num of swivelchairs Images: \", len(swivelchair_list))\r\n",
        "    print(\"Num of tables Images: \", len(tables_list))\r\n",
        "    print(\"--Test Images--\")\r\n",
        "    print(\"Num of Images: \", len(test_images))\r\n",
        "\r\n",
        "    # 레이블 구분\r\n",
        "    class_to_int = {\"bed\": 0, \"chair\": 1, \"sofa\": 2, \"swivelchair\": 3, \"table\": 4}\r\n",
        "    int_to_class = {0: \"bed\", 1: \"chair\", 2: \"sofa\", 3: \"swivelchair\", 4: \"table\"}\r\n",
        "    #classes = {'bed', 'chair', 'sofa', 'swivelchair', 'table'}\r\n",
        "\r\n",
        "    # 데이터 셋 생성\r\n",
        "    train_dataset = FurnitureDataset(train_images, class_to_int, mode='train', transforms=transform)\r\n",
        "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\r\n",
        "\r\n",
        "    test_dataset = FurnitureDataset(test_images, class_to_int, mode='test', transforms=transform)\r\n",
        "    testloader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0)\r\n",
        "\r\n",
        "    # net = Net()\r\n",
        "    net = CNN()\r\n",
        "\r\n",
        "    criterion = nn.CrossEntropyLoss()\r\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\r\n",
        "    device = 'cuda'\r\n",
        "    # device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "    print (device,\"로 학습\")\r\n",
        "\r\n",
        "    # 신경망 학습하기\r\n",
        "    for epoch in range(2):\r\n",
        "        running_loss = 0.0\r\n",
        "        for i, data in enumerate(trainloader,0):\r\n",
        "            inputs, labels = data  # data입력\r\n",
        "            optimizer.zero_grad()  # gradient 매개변수를 0으로 만듬\r\n",
        "            # 순전파 + 역전파 + 최적화\r\n",
        "            outputs = net(inputs)\r\n",
        "            loss = criterion(outputs, labels)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            # 통계출력\r\n",
        "            running_loss += loss.item()\r\n",
        "            if i % 2000 == 1999:\r\n",
        "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\r\n",
        "                running_loss = 0.0\r\n",
        "    print('Finished Training')\r\n",
        "    PATH = './cifar_net.pth'\r\n",
        "    torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Train Images--\n",
            "Num of All Images:  1722\n",
            "Num of Beds Images:  900\n",
            "Num of chairs Images:  634\n",
            "Num of sofas Images:  60\n",
            "Num of swivelchairs Images:  89\n",
            "Num of tables Images:  39\n",
            "--Test Images--\n",
            "Num of Images:  423\n",
            "cuda 로 학습\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-bdc8cb1dc116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m  \u001b[0;31m# data입력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# gradient 매개변수를 0으로 만듬\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 224, 224] at entry 0 and [1, 224, 224] at entry 2"
          ]
        }
      ]
    }
  ]
}