{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hist_cmp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coreight98/Paran_ajou_Project_Anything/blob/main/image_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDZtxcYX1agg"
      },
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "GoogleNet = models.googlenet(pretrained=True)\n",
        "GoogleNet.fc = nn.Linear(in_features=1024, out_features=35)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ob1SJaA1kwM",
        "outputId": "62fdaac8-5174-43a2-8a50-59ecfe88918d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import time\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import random\n",
        "import torch"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLpb1r4d1wQv"
      },
      "source": [
        "train_location = '/content/drive/MyDrive/data/DTD_final/'\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "class PatternDataset():\n",
        "    def __init__(self, image, mode, transforms):\n",
        "        super().__init__()\n",
        "        self.image = image\n",
        "        self.mode = mode\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.image[index]\n",
        "        image = Image.open(train_location + image_name)\n",
        "        image = image.resize((224,224))\n",
        "        #레이블 입력\n",
        "        label = 1\n",
        "        label = torch.tensor(label,dtype=torch.long)\n",
        "        #이미지 변형 적용용\n",
        "        image = self.transforms(image)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image)\n",
        "    def ind(index):\n",
        "      image=self.image[index]\n",
        "      return image\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAjOtwpzDdEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce8c671-8026-48a6-e637-b0d458f22b21"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    device ='cuda'\n",
        "    if device == 'cuda':\n",
        "      torch.cuda.manual_seed_all(777)\n",
        "    SEED = 777\n",
        "    seed_everything(SEED)\n",
        "    #데이터 셋 불러오고 정규화\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "          ]\n",
        "    )\n",
        "    train_images = os.listdir(train_location)\n",
        "    net=GoogleNet\n",
        "    PATH = '/content/drive/MyDrive/data/DTD_save/YG/New_GN/GGN_69.pth'\n",
        "    net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "    net.eval()\n",
        "    X = np.load('/content/drive/MyDrive/data/DTD_save/DTD10.npy')\n",
        "    X = np.reshape(X,(3624,35))\n",
        "    Y = np.zeros((3624,1))\n",
        "    Y = np.reshape(Y,(3624,1))\n",
        "    reg = KNeighborsClassifier(n_neighbors=4)\n",
        "    reg.fit(X,Y)\n",
        "    \n",
        "    input_pth = '/content/drive/MyDrive/data/DTD_final/braided_0001.jpg'\n",
        "    img = PIL.Image.open(input_pth) ##################여기가 input image입니다요\n",
        "    img = img.resize((224,224))\n",
        "    emp = torch.empty((1,3,224,224),dtype=torch.float32)\n",
        "    img_t =transform(img)\n",
        "    emp[0] = img_t\n",
        "    input = net(emp)\n",
        "    neighbor_index= reg.kneighbors(input.detach().numpy(),n_neighbors=4,return_distance=False)\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n5uRSUFiEmx"
      },
      "source": [
        "##### 아웃풋 이미지 4장 출력 #####\n",
        "from IPython.display import Image \n",
        "for ind in neighbor_index[0]:\n",
        "  name='/content/drive/MyDrive/data/DTD_final/%s'%(train_images[ind])\n",
        "from PIL import Image"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4r3qhjI2HLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d526c8-59b8-472d-e870-a716dcb570ef"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "\n",
        "%cd /content/yolov5/\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 6469, done.\u001b[K\n",
            "remote: Counting objects: 100% (187/187), done.\u001b[K\n",
            "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
            "remote: Total 6469 (delta 97), reused 113 (delta 46), pack-reused 6282\u001b[K\n",
            "Receiving objects: 100% (6469/6469), 8.69 MiB | 35.86 MiB/s, done.\n",
            "Resolving deltas: 100% (4404/4404), done.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Collecting PyYAML>=5.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.9.1+cu101)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (4.41.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (2.5.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.1.5)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (2.0.2)\n",
            "Collecting thop\n",
            "  Downloading https://files.pythonhosted.org/packages/6c/8b/22ce44e1c71558161a8bd54471123cc796589c7ebbfc15a7e8932e522f83/thop-0.0.31.post2005241907-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (3.7.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.12.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.30.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.3.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.34.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (56.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 20)) (2018.9)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0->-r requirements.txt (line 29)) (0.29.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.0.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.0.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.4.1)\n",
            "Installing collected packages: PyYAML, thop\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1 thop-0.0.31.post2005241907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FV7EuMS2NAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd28adc0-5db7-4b7f-ba1c-d90c1dc1d217"
      },
      "source": [
        "from glob import glob\n",
        "val_imgg_list = glob('/content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/*.jpg')\n",
        "\n",
        "val_img_path = val_imgg_list[0:10]\n",
        "weights_path = '/content/drive/MyDrive/data/DTD_save/best.pt'\n",
        "for item in val_img_path:\n",
        "  !python detect.py --weights \"{weights_path}\" --img 416 --conf 0.3 --source \"{item}\" --save-txt "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_1.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 🚀 v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_1.jpg: 416x416 1 chair, Done. (0.073s)\n",
            "Results saved to runs/detect/exp\n",
            "1 labels saved to runs/detect/exp/labels\n",
            "Done. (0.449s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_67.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 🚀 v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_67.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp2\n",
            "1 labels saved to runs/detect/exp2/labels\n",
            "Done. (0.247s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_62.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 🚀 v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_62.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp3\n",
            "1 labels saved to runs/detect/exp3/labels\n",
            "Done. (0.319s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_98.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 🚀 v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_98.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp4\n",
            "1 labels saved to runs/detect/exp4/labels\n",
            "Done. (0.374s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_123.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 🚀 v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_123.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp5\n",
            "1 labels saved to runs/detect/exp5/labels\n",
            "Done. (0.288s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_93.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 🚀 v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_93.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp6\n",
            "1 labels saved to runs/detect/exp6/labels\n",
            "Done. (0.285s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_145.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 🚀 v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_145.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp7\n",
            "1 labels saved to runs/detect/exp7/labels\n",
            "Done. (0.299s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_9.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 🚀 v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_9.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp8\n",
            "1 labels saved to runs/detect/exp8/labels\n",
            "Done. (0.265s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_22.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 🚀 v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_22.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp9\n",
            "1 labels saved to runs/detect/exp9/labels\n",
            "Done. (0.289s)\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, hide_conf=False, hide_labels=False, img_size=416, iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=True, source='/content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_45.jpg', update=False, view_img=False, weights=['/content/drive/MyDrive/data/DTD_save/best.pt'])\n",
            "YOLOv5 🚀 v5.0-115-g407dc50 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7067395 parameters, 0 gradients, 16.4 GFLOPS\n",
            "image 1/1 /content/drive/MyDrive/파란학기/가구 이미지_최종/images/라탄암체어/라탄암체어_45.jpg: 416x416 1 chair, Done. (0.009s)\n",
            "Results saved to runs/detect/exp10\n",
            "1 labels saved to runs/detect/exp10/labels\n",
            "Done. (0.250s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAIarvvA4yVw"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob\n",
        "\n",
        "output = []\n",
        "\n",
        "for i in range(1,len(val_img_path)+1):\n",
        "  if i == 1 :\n",
        "    path = '/content/yolov5/runs/detect/exp/labels/*'\n",
        "    file_list = glob.glob(path)\n",
        "  else:\n",
        "    path = '/content/yolov5/runs/detect/exp%d/labels/*'%i\n",
        "    file_list = glob.glob(path)\n",
        "  try:\n",
        "    path = file_list[0]\n",
        "    f = open(path, 'r')\n",
        "    lines = f.readlines()\n",
        "    if len(lines)>=2:\n",
        "      continue\n",
        "  except:\n",
        "    continue\n",
        "  src = cv2.imread(val_img_path[i-1], cv2.IMREAD_COLOR)\n",
        "  k=1\n",
        "  for line in lines:\n",
        "      token = line.split(' ')\n",
        "      x=float(token[1])\n",
        "      y=float(token[2])\n",
        "      w=float(token[3])\n",
        "      h=float(token[4])\n",
        "\n",
        "      x1=x-w/2\n",
        "      y1=y-h/2\n",
        "      \n",
        "      x1_pixel = int(x1*src.shape[1])\n",
        "      w_pixel = int(w*src.shape[1])\n",
        "      y1_pixel = int(y1*src.shape[0])\n",
        "      h_pixel = int(h*src.shape[0])\n",
        "      \n",
        "      rectangle = (x1_pixel,y1_pixel,w_pixel,h_pixel)\n",
        "\n",
        "      mask = np.zeros(src.shape[:2], np.uint8)\n",
        "\n",
        "      bgdModel = np.zeros((1, 65), np.float64)\n",
        "      fgdModel = np.zeros((1, 65), np.float64)\n",
        "\n",
        "      cv2.grabCut(src, # 원본 이미지\n",
        "            mask,       # 마스크\n",
        "            rectangle,  # 사각형\n",
        "            bgdModel,   # 배경을 위한 임시 배열\n",
        "            fgdModel,   # 전경을 위한 임시 배열\n",
        "            5,          # 반복 횟수\n",
        "            cv2.GC_INIT_WITH_RECT) # 사각형을 위한 초기화\n",
        "\n",
        "      mask_2 = np.where((mask==2) | (mask==0), 0, 1).astype('uint8')\n",
        "\n",
        "      image_rgb_nobg = src * mask_2[:, :, np.newaxis]\n",
        "      A = image_rgb_nobg[y1_pixel:(y1_pixel+h_pixel),x1_pixel:(x1_pixel+w_pixel)]\n",
        "      output.append([A,i])\n",
        "  f.close()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej9M6r0dFcAR"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "ans_arr = []\n",
        "for i in range(len(output)):\n",
        "  for j in range(4):\n",
        "    name='/content/drive/MyDrive/data/DTD_final/%s'%(train_images[neighbor_index[0][j]])\n",
        "    img1 = cv2.imread(name,0)\n",
        "    img2 = output[i][0]\n",
        "    orb = cv2.ORB_create()\n",
        "    kp1, des1 = orb.detectAndCompute(img1,None)\n",
        "    kp2, des2 = orb.detectAndCompute(img2,None)\n",
        "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "    matches = bf.match(des1,des2)\n",
        "    matches = sorted(matches, key = lambda x:x.distance)\n",
        "    if len(matches) > 120:\n",
        "      ans_arr.append(output[i][1])\n",
        "      img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:10],None,flags=2)\n",
        "      break"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMtv2EkbLeg_"
      },
      "source": [
        "import matplotlib.image as img \n",
        "import matplotlib.pyplot as pp \n",
        "\n",
        "for i in ans_arr:\n",
        "  ndarray = img.imread(val_imgg_list[i-1]) \n",
        "  \n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}